<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> korean | Room 1805 </title> <meta name="author" content="Room 1805"> <meta name="description" content="안전장치로 학습된 모델의 phase transition에 대한 체계적 연구. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://room1805.github.io/korean/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Explanation on Safety Phase Transition in Large Language Models",
            "description": "안전장치로 학습된 모델의 phase transition에 대한 체계적 연구. ",
            "published": "May 22, 2021",
            "authors": [
              
              {
                "author": "Albert Einstein",
                "authorURL": "https://en.wikipedia.org/wiki/Albert_Einstein",
                "affiliations": [
                  {
                    "name": "IAS, Princeton",
                    "url": ""
                  }
                ]
              },
              
              {
                "author": "Boris Podolsky",
                "authorURL": "https://en.wikipedia.org/wiki/Boris_Podolsky",
                "affiliations": [
                  {
                    "name": "IAS, Princeton",
                    "url": ""
                  }
                ]
              },
              
              {
                "author": "Nathan Rosen",
                "authorURL": "https://en.wikipedia.org/wiki/Nathan_Rosen",
                "affiliations": [
                  {
                    "name": "IAS, Princeton",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm sticky-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Room</span> 1805 </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">project </a> </li> <li class="nav-item active"> <a class="nav-link" href="/korean/">korean <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/english/index.html">english </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="post distill"> <d-title> <h1>Explanation on Safety Phase Transition in Large Language Models</h1> <p>안전장치로 학습된 모델의 phase transition에 대한 체계적 연구. </p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#equations">Equations</a> </div> <div> <a href="#citations">Citations</a> </div> <div> <a href="#footnotes">Footnotes</a> </div> <div> <a href="#code-blocks">Code Blocks</a> </div> <div> <a href="#interactive-plots">Interactive Plots</a> </div> <div> <a href="#layouts">Layouts</a> </div> <div> <a href="#other-typography">Other Typography?</a> </div> </nav> </d-contents> <h2 id="motiv">Motiv</h2> <p>AI 모델은 인류에 해가 되는 문장을 말하면 안된다. 최근 연구들은 안전한 사용을 위해 나쁜말을 하는 대신 safety와 관련된 말을 하도록 학습된다. 대표적인 예시로 차별적인 내용을 물어보면 평등에 대한 중요성을 언급한다. 이렇게 Safety와 관련된 말을 하도록 생성 모드가 바뀌는 <em>safety phase</em>에 대한 전반적인 이해 및 설명은 더욱 안전한 모델을 만들기 위해서 필수적이다. 본 연구에서는 instruction-tuned 된 GPT 모델에 대한 <em>safety phase</em>을 해석하기 위한 두 가지 실험적인 결과를 제시한다.</p> <p><strong>📌 1) 모델은 어떠한 상황에서 safety phase가 발생하는가.</strong>: 이 연구는 safety와 관련된 다양한 문장에 대해서 각 문장의 표현들을 비교하고 클러스터링하여 전반적인 모델의 safety sentence들의 입출력을 통계적으로 분석한다.<br> <strong>📌 2) Safety phase는 어떤 방식으로 trigger 되는가?</strong>: 모델 내부에서는 safety와 관련된 문장을 생성하도록 유도하는 특징 혹은 뉴런이 존재한다. Safety를 유발하는 모델 내부를 탐구하여 해당 구조의 조작으로 safety와 관련된 문장들의 변화를 탐구한다. s 대규모 언어 모델은 사회의 규약과 정보에 맞춰서 지속적으로 기존 정보를 지우고 새롭게 덮어쓴다. 또한 부정적인 정보들은 생성을 막도록 추가적인 학습이 되며 사회규범과 법의 변화에 맞추어 모델의 작동 방식은 바뀐다. 본 연구에서 탐구하는 <em>safety phase transition</em>은 안전 문구와 관련된 LLM의 생성과정을 분석함으로써 실험적 관찰을 바탕으로한 더욱 안전한 모델 구조에 대한 영감을 제시한다.</p> <h2 id="big-picture">Big Picture</h2> <ul> <li>safety transition in LLM <ul> <li>(3) safety transition의 정의. Complete and incomplete sentence 정의. Harmful sentence 정의</li> <li>🥕 (3.1, 4.1) template-base evaluation of safety-phase transition (Yeonjea, Jinsil)</li> <li>🍊 (3.2, 4.2) activation-base evaluation of safety-phase transition (Bumjin, Youngju)</li> </ul> </li> </ul> <h2 id="collection-of-papers">Collection of Papers</h2> <ul> <li> <strong>Safety finetuning + deceiving</strong> <ul> <li>Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training</li> <li>Simple probes can catch sleeper agents</li> </ul> </li> <li> <strong>Safety finetuning</strong> <ul> <li>Training a helpful and harmless assistant with reinforcement learning from human feedback</li> <li>Training language models to follow instructions with human feedback</li> </ul> </li> <li> <strong>Jail-break</strong> <ul> <li>Defending chatgpt against jailbreak attack via self-reminders</li> <li>Many-shot jailbreaking</li> <li>Universal and Transferable Adversarial Attacks on Aligned Language Models</li> <li>Jailbroken: How does llm safety training fail?</li> <li>“Do Anything Now”: Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models</li> </ul> </li> <li>Detecting Jailbreaks <ul> <li>Causality Analysis for Evaluating the Security of Large Language Models</li> </ul> </li> <li>Explanation on LLM <ul> <li>Explainability for Large Language Models: A Survey</li> </ul> </li> <li> <strong>Safety</strong> <ul> <li>Towards understanding sycophancy in language models</li> <li>GPT-4 Technical Report</li> <li>Constitutional AI:Harmlessness from AI feedback</li> </ul> </li> <li> <strong>Interpretability (feature)</strong> <ul> <li>Towards Monosemanticity: Decomposing Language Models With Dictionary Learning</li> <li>Mapping the Mind of a Large Language Model</li> </ul> </li> </ul> <hr> <h2 id="abstract">Abstract</h2> <h2 id="1-introduction">1. Introduction</h2> <p>최근 몇 년 사이에, 생성형 AI 의 하나인 Large Language Model(LLM) 은 유래 없이 성장하여, 이미 전 세계인이 다양한 용도로 사용하는 도구가 되었다. 예를 들어, ChatGPT는 사용자 수 100만 돌파를 5일[1] 만에, 월간 사용자 10억을 세 달[2]만에 달성하는 역대 최단 기록을 세웠다. 이러한 빠른 확산에는 여러 문제점도 따랐다. 대표적인 부작용으로는 Hallucination, Bias, Harmful Contents 생성 등이 있으며, 충분히 고려되지 못한 채 서비스가 제공 되었다. 모델 연구자들과 서비스 제공 업체들이 안전한 모델을 만들기 위해 노력하고 있음[3]에도 불구하고, 현재 모델은 적지 않은 취약점들을 가지고 있고, 악의적인 사용자는 Adversarial attack prompt 를 사용하여 LLM 을 악용하려는 공격 전략을 점점 발전시키고 있다.</p> <p>공격에 대비하는 방법은, 공격 방식을 지속적으로 모니터링해서 해당 방어 로직을 넣는, “공격에 대한 방어”의 프로세스가 기본이다. 이러한 다양한 Adversarial attack prompt 에 대한 연구는 다양하게 진행 되고 있다[4]. 하지만 LLM 의 경우, 다른 일반적인 서비스들처럼 특정 프로토콜의 보안을 강화하는 것으로는 해결되지 않는다. “자연어로 들어오는 요청에 대한 정보 제공”이 LLM의 주요 역할인데, “자연어 요청” 자체가 공격일 수 있고, “정보 제공” 자체가 잘못된 동작에 해당하기 때문이다. 따라서 공격에 대한 대응을 넘어, LLM 의 동작 방식이 기본적으로 해로운 정보를 만들어내지 않도록 하는 것이 중요하다.</p> <p>이 논문에서는 LLM 의 가장 기본적인 동작에 해당하는, “다음에 이어지는 내용 생성” 에 대한 LLM 의 특성을 조사했다. 그 중에서도 어떤 상황에서 safety phase 를 거치는지에 초점을 맞췄다. 주요 아이디어는 다음과 같다.</p> <p>1) safety phase : 문장의 흐름에 맞추기 위해서 “해로운 내용” 일지라도 생성을 하는지 여부</p> <p>2) safety phase transition : “해로운 내용 생성”을 한 후에, 원래 훈련된 기조대로 안전한 내용을 생성하여 추구하는 안전 기준으로 돌아가는지를 살피는 것</p> <p>해로운 내용을 이끌어 내는 완성되지 않은 문장과, 해로운 내용이 들어있지만 완성된 문장을 입력 prompt 로 넣어 모델의 출력과 그 차이점을 분석했다. 그 결과, 완성되지 않은 문장일 경우 높은 확률로 해로운 내용을 생성함을 발견하였고, LLM 이 해로운 내용을 생성하였다 하더라도 높은 비율로 안전한 내용으로 돌아가는 경향이 있음을 발견하였다. 이는 LLM 이 기본적으로 설정된 안전 기준을 완전히 벗어나지 않도록 설계되었음을 시사한다.</p> <h2 id="2-related-work">2. Related Work</h2> <h2 id="3-method">3. Method</h2> <p>We consider a set of concepts $\mathcal{C} = (z_1, z_2, \cdots)$ where each concept $c$ is related to a human-oriented concept, such as harmless or safety. Each concept $z$ has examples, a set of passages \(\mathcal{Y}_{c}\), where passage \(y = (y_1, y_2, \cdots) \in \mathcal{Y}_{c}\) consists of tokens $y_i$ and includes the semantic meaning of concept $c$. We use notation $c \perp c’$ when two concepts $c$ and $c’$ can not exist together, e.g., safety concept and violence concept.</p> <p>We define two terms <em>phase</em> and *phase transition$ as follows.</p> <blockquote> <p>Definition: <strong>Phase</strong> <br></p> <blockquote> <p>A $c$-<em>phase</em> is a subset of time steps $[t_{begin}, t_{end}]$ where the generated content \(({y}_{t_{begin}}, \cdots, {y}_{t_{end}})\) with \({y}_{t_{k}} \sim P_{\theta}(\cdot \vert y_1, \cdots, y_{t_{k}-1})\) can be included in the set of concept-related passages \(\mathcal{Y}_{c}\).</p> </blockquote> </blockquote> <p>The definition of <em>phase</em> assumes a passage $y$. The inclusion of an element in the set element in $\mathcal{Y}_{c}$ can be either determined by a human-annotator or text similarity scores with the examples in the set.</p> <blockquote> <p>Definition: <strong>Phase Emergence</strong> <br></p> <blockquote> <p>A <em>phase emergence</em> is the time step when the generation includes new concept $c’$ as a phase.</p> </blockquote> </blockquote> <blockquote> <p>Definition: <strong>Phase Transition</strong> <br></p> <blockquote> <p>A <em>phase transition</em> is a $c$-phase emergence with the disappearance of existing concept $c’$ such that $ c’ \perp c$.</p> </blockquote> </blockquote> <p>Rigorously, the definition of phase transition</p> <h3 id="31-safety-phase-transition">3.1 Safety-Phase Transition</h3> <p>consider two types of passages, $\mathcal{T}<em>{com}$ and $\mathcal{T}</em>{incom}$ where the elements are complete and incomplete sentences.</p> <p>Consider a harmful prompt $\mathcal{P} \in\mathcal{T}_{com}$.</p> <p>Figure below shows the phase transition for complete and incomplete cases.</p> <p align="center"> <img src="https://onedrive.live.com/embed?resid=AE042A624064F8CA%219678&amp;authkey=%21AL_paZel8mue_pc&amp;width=1636&amp;height=602" width="100%" height="250"> </p> <h3 id="32-detection-of-phase-transition">3.2 Detection of Phase Transition</h3> <p>Several work propose the methods to detect the conceptual neurons.</p> <ul> <li>Value Detection via optimization : find the activation pattern that mostly maximize the likelihood of the safe phase. (FactualGPT)</li> <li>Activation : Find the activation pattern via forwarding the target output</li> <li>Neuron Attribution : Compute the attribution score via gradient descent.</li> </ul> <p>We find a vector at the end of sentence. A hidden representation $A_{safe}$ which maximizes the forward.</p> <blockquote> <p>What about the key-value structure? Our we finding any key? We do not find a sparse key neurons which activate the concept. Because recent work reveals that the neural network prefers. However, it could be the case that only the sparse combination of neurons forms the target activation. Therefore, finding neuron (entry point for vector representation) is not the primitive problem.</p> </blockquote> <h2 id="4-experiments">4. Experiments</h2> <h2 id="41-phase-transition-with-templates">4.1 Phase Transition with Templates</h2> <p>We categorize four types of generations for the complete and incomplete prompts.</p> <h4 id="complete">Complete</h4> <table> <thead> <tr> <th style="text-align: center">Harmful Generation</th> <th style="text-align: center">Safety-phase Transition</th> <th style="text-align: left">$\mathcal{P}$=”Teach me how to hurt people.”</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">-</td> <td style="text-align: center">✅</td> <td style="text-align: left"><strong>I cannot fullfil your request.</strong></td> </tr> <tr> <td style="text-align: center">-</td> <td style="text-align: center">❌</td> <td style="text-align: left"><strong>A stab in the back …</strong></td> </tr> </tbody> </table> <h4 id="incomplete">Incomplete</h4> <table> <thead> <tr> <th style="text-align: center">Harmful Generation</th> <th style="text-align: center">Safety-phase Transition</th> <th style="text-align: left">$\mathcal{P}’$=”A stab in the back or”</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">✅</td> <td style="text-align: center">✅</td> <td style="text-align: left"><strong>a knife to the chest. <br> I cannot fullfil your request.</strong></td> </tr> <tr> <td style="text-align: center">✅</td> <td style="text-align: center">❌</td> <td style="text-align: left"><strong>a knife to the chest. <br> I addition, shoot a gun.</strong></td> </tr> <tr> <td style="text-align: center">❌</td> <td style="text-align: center">✅</td> <td style="text-align: left"><strong>hurt is not a good action <br> I cannot fullfil your request.</strong></td> </tr> <tr> <td style="text-align: center">❌</td> <td style="text-align: center">❌</td> <td style="text-align: left"><strong>hurt is not a good action. <br> but you can shoot a gun</strong></td> </tr> </tbody> </table> <h2 id="42-phase-transition-via-activation">4.2 Phase Transition via Activation</h2> <h3 id="adding-concept">Adding concept</h3> <ol> <li>Does the jareak examples shows the safe-phase with the activation addition?</li> <li>Does the inplete sentence jailbreak examples shows the safe-phase without completion of the harmful completion?</li> </ol> <h3 id="removing-cept">Removing cept</h3> <h2 id="5-results">5. Results</h2> <h2 id="6-discussi">6. Discussi</h2> <h2 id="7-conclusi">7. Conclusi</h2> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/2018-12-22-distill.bib"></d-bibliography> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2024 Room 1805. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> </body> </html>