---
layout: about
title: project
permalink: /
subtitle: Trustworthy AI project in KAIST-SAIL

profile:
  align: right
  image: room1802_v2.jpg
  image_circular: false # crops the image to make it circular
  more_info: >
    <p>This Legendary Project</p>
    <p>Began In</p>
    <p>Room 1805</p>

news: false # includes a list of news items
selected_papers: false # includes a list of papers marked as "selected={true}"
social: false # includes social icons at the bottom of the page
---
<style>
.text {
  font-family: "Times New Roman";
}
</style>

AI 모델은 날이 갈수록 더 많은 사회적인 영향력을 보여주고 있기에, 그들의 행동과정을 명확하게 이해하는 것은 AI 모델의 영향력을 더욱 컨트롤 할 수 있는 길입니다. 이 방에 모인 사람들은 AI 모델을 이해하고 그들의 약점을 파악하여 더 나은 AI 시스템을 만드는 목적으로 이 연구를 시작하였습니다. 

특히, 최신의 거대 언어 모델(LLM: Large Language Model)은 인간의 언어를 더 정교하게 이해하고 생성할 수 있게 되면서, 새로운 가능성과 도전 과제를 동시에 안겨주고 있습니다. 이 연구는 AI가 인간의 삶에 미치는 긍정적 영향을 극대화하고 부정적 결과를 최소화하는 데 초점을 맞추고 있습니다. 

비록 현재 AI 기술이 많은 진보를 이루었지만, 여전히 많은 부분에서 인간의 감성과 윤리적 판단이 필요합니다. <strong>Room 1805</strong> 프로젝트는 이러한 문제를 해결하기 위해 다양한 전문가와 협력하여, AI 모델의 결함을 보완하고 더욱 신뢰할 만한 시스템을 구축하고자 합니다. 또한, 이 연구는 AI가 인간의 삶에 미치는 긍정적 영향을 극대화하고 부정적 결과를 최소화하는 데 초점을 맞추고 있습니다. 궁극적으로, <strong>Room 1805</strong> 프로젝트는 AI와 인간이 조화롭게 공존하는 미래를 그리고 있습니다.
<hr>


## Safety 

<ul>
  <li> 📜 <strong>Room 1805</strong>: <text class="text"> <a href="/room1805"> Incomplete Prompt Jailbreak </a> </text> </li>
  <li> 📜 <strong>Room 1806</strong>: <text class="text"> <a href="/room1806"> Representation Interpretation of Refusal Mechanism In Large Language Models </a>  </text>  </li>
  
</ul>


## Other LLMs

<li> 📜 <strong>ICPRAI 2024 </strong>: <text class="text"> <a href="https://fxnnxc.github.io/main_papers/2024_icprai_source_identification/"> Identifying the source of documents in LLMs  </a>  </text>  </li>
<li> 📜 <strong>IJCAI 2024 </strong>: <text class="text"> <a href="https://fxnnxc.github.io/main_papers/2024_guidace_loss_for_documents/"> Memorizing Documents with Guidance in LLMs  </a>  </text>  </li>
    

