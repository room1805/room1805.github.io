---
layout: distill
permalink: /room1806/
title: 'korean'
post_title: 'Representation Interpretation of Refusal Mechanism In Large Language Models'
description: '' 
tags: distill
giscus_comments: false
date: 2021-05-22
featured: true
nav: false
nav_order: 1
pagination:
  enabled: false
authors:
  - name: Bumjin Park
    affiliations:
        name: KAIST
  - name: Yeonjea Kim
    affiliations:
      name: KAIST
  - name: Jinsil Lee
    affiliations:
      name: KAIST
  - name: Youngju Joung
    affiliations:
      name: KAIST
  - name: Jaesik Choi
    affiliations:
      name: KAIST
bibliography: all.bib
# Below is an example of injecting additional post-specific styles.
# If you use this post as a template, delete this _styles block.
_styles: >
  .fake-img {
    background: #bbb;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
    margin-bottom: 12px;
  }
  .fake-img p {
    font-family: monospace;
    color: white;
    text-align: left;
    margin: 12px 0;
    text-align: center;
    font-size: 16px;
  }

---

* 🧑🏻‍💻 Paper: [drive](https://1drv.ms/b/s!Asr4ZEBiKgSu31tqfZFXUAwuBzmo?e=gHKzl6)
* 🍊 This work is presented in KCC 2024 XAI Workshop

---

## 소개 

모든 기계가 입력에 대해서 출력을 가지듯이 AI 모델도 입력에 반응해서 출력을 제공합니다. 한 가지 차이점이 있다면, 기계는 그 과정을 사람이 설계하고 데이터가 흐르도록 만들지만, AI는 학습을 통해서 자연스럽게 내부 메커니즘이 형성됩니다. AI모델의 내부가 벡터로 구성되어 있다는 점에서 벡터를 해석한다면, 알지못하는 모델 내부를 해석할 수 있습니다. 

이 연구에서는 AI모델이 해로운 질문에 대해서 거절하는 메커니즘에 대한 관찰적 결과들을 공유합니다. 
특히 이전 [room1805]에서 소개한 *문장이 끝날 때 거절이 발생한다*는 점으로 미뤄봤을 때, 문장의 중간에서 발생하는 거절과 문장을 마치고 생성하는 거절은 어쩐지 다른 메커니즘인 것 같습니다. 

<img src="/assets/img/room1806/1.png" style="width:100%">


## 프롬프트, 거절 생성 위치 

연구 결과를 확인하기 전에 고려할 게 있습니다. LLM은 단어들을 순차적으로 처리하는 autoregressive 모델입니다. 거절은 토큰들의 어떤 위치에서도 시작될 수 있고, 입력으로 주어지는 프롬프트에 따라서 거절 문장 생성은 크게 영향을 받습니다. 그래서 본 연구에서는 프롬프트 타입과 문장으로 구분되는 거절 위치에 대한 가정을 세우고, 거절 벡터들을 분석했습니다. 

<img src="/assets/img/room1806/2.png" style="width:100%">

### 관찰 1: 거절 표현 유사성
> 거절 방식에 따라서 (1) 유사하거나 (2) 다른 내부 표현이 있다. 

<img src="/assets/img/room1806/3.png" style="width:100%">

### 관찰 2: 거절 위치
> 문장을 마치고 거절하는 것은, 중간에 거절하는 것과 내부 표현이 다르다. 

<img src="/assets/img/room1806/4.png" style="width:100%">

### 관찰 3: 거절 표현 intervention
> 거절 벡터를 더할 때, 강건한 벡터가 존재한다. 

<img src="/assets/img/room1806/5.png" style="width:100%">

### 관찰 4: 거절 표현과 유사도 
> 해롭지 않은 문장에 대해서도 활성화가 일부 된다. 

<img src="/assets/img/room1806/6.png" style="width:100%">


## 결론 

LLM의 최근 연구들은 모델 내부의 해석에 집중하고 있습니다. 과거에는 고차원 벡터에 대한 해석이 불가능하다는 인식이 강했지만, 현재는 모델 내부를 해석하여 벡터들을 찾고, 그들의 영향력을 측정하거나 수정하는 연구가 많이 진행되고 있습니다. 이 연구는 거절 매커니즘을 해석하는 초기 연구입니다. 앞으로 더 많이 연구될 거절 매커니즘의 해석 방법을 기대해주세요!